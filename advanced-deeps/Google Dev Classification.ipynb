{"cells":[{"cell_type":"code","execution_count":12,"metadata":{"executionInfo":{"elapsed":20,"status":"ok","timestamp":1680952948870,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"},"user_tz":-330},"id":"oIqvW07lelx1"},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import os\n","import re\n","import shutil\n","import string\n","import tensorflow as tf\n","import random\n","import numpy as np\n","\n","from tensorflow.keras import layers\n","from tensorflow.keras import losses"]},{"cell_type":"code","execution_count":13,"metadata":{"executionInfo":{"elapsed":49715,"status":"ok","timestamp":1680952998568,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"},"user_tz":-330},"id":"69P1f5wcekBy"},"outputs":[],"source":["url = \"https://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\"\n","\n","dataset = tf.keras.utils.get_file(\"aclImdb_v1\", url,\n","                                    untar=True, cache_dir='.',\n","                                    cache_subdir='')\n","\n","dataset_dir = os.path.join(os.path.dirname(dataset))"]},{"cell_type":"markdown","metadata":{"id":"8tDa4yIFdzxj"},"source":["## Load the Dataset"]},{"cell_type":"code","execution_count":14,"metadata":{"executionInfo":{"elapsed":52,"status":"ok","timestamp":1680952998570,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"},"user_tz":-330},"id":"km_i1a1xdr57"},"outputs":[],"source":["def load_imdb_sentiment_analysis_dataset(data_path, seed=123):\n","  \"\"\"Loads the IMDb movie reviews sentiment analysis dataset.\n","\n","  # Arguments\n","    data_path: string, path to the data directory.\n","    seed: int, seed for randomizer\n","\n","  # Returns\n","    A tuple of training and validation data.\n","    Number of training samples: 25000\n","    Number of test samples: 25000\n","    Number of categories: 2 (0 - negative, 1 - positive)\n","\n","  # References\n","        Mass et al., http://www.aclweb.org/anthology/P11-1015\n","\n","        Download and uncompress archive from:\n","        http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz\n","  \"\"\"\n","  imdb_data_path = os.path.join(data_path, 'aclImdb')\n","\n","  # Load the training data\n","  train_texts = []\n","  train_labels = []\n","  for category in ['pos', 'neg']:\n","    train_path = os.path.join(imdb_data_path, 'train', category)\n","    for fname in sorted(os.listdir(train_path)):\n","      if fname.endswith('.txt'):\n","        with open(os.path.join(train_path, fname)) as f:\n","          train_texts.append(f.read())\n","        train_labels.append(0 if category == 'neg' else 1)\n","  \n","  # Load the test data.\n","  test_texts = []\n","  test_labels = []\n","  for category in ['pos', 'neg']:\n","    test_path = os.path.join(imdb_data_path, 'test', category)\n","    for fname in sorted(os.listdir(test_path)):\n","      if fname.endswith('.txt'):\n","        with open(os.path.join(test_path, fname)) as f:\n","          test_texts.append(f.read())\n","        test_labels.append(0 if category == 'neg' else 1)\n","\n","  # Shuffle the training data and labels.\n","  random.seed(seed) \n","  random.shuffle(train_texts)\n","  random.seed(seed)\n","  random.shuffle(train_labels)\n","\n","  return ((train_texts, np.array(train_labels)),\n","          (test_texts, np.array(test_labels)))"]},{"cell_type":"code","execution_count":15,"metadata":{"executionInfo":{"elapsed":1627,"status":"ok","timestamp":1680953000185,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"},"user_tz":-330},"id":"fKtOvIQpg2uS"},"outputs":[],"source":["data = load_imdb_sentiment_analysis_dataset(dataset_dir)"]},{"cell_type":"code","execution_count":16,"metadata":{"executionInfo":{"elapsed":51,"status":"ok","timestamp":1680953000188,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"},"user_tz":-330},"id":"szqf5mr1hOlF"},"outputs":[],"source":["(train_texts, train_labels), (test_texts, test_labels) = data"]},{"cell_type":"code","execution_count":17,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":123},"executionInfo":{"elapsed":50,"status":"ok","timestamp":1680953000190,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"},"user_tz":-330},"id":"VFgNOlaDhgRg","outputId":"46e967fd-ec73-4b3d-d1db-2f26e149f8af"},"outputs":[{"data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["\"POSSIBLE SPOILERS\u003cbr /\u003e\u003cbr /\u003eThe Spy Who Shagged Me is a muchly overrated and over-hyped sequel. International Man of Mystery came straight out of the blue. It was a lone star that few people had heard of. But it was stunningly original, had sophisticated humour and ample humour, always kept in good taste, and had a brilliant cast. The Spy Who Shagged Me was a lot more commercially advertised and hyped about.\u003cbr /\u003e\u003cbr /\u003eOK I'll admit, the first time I saw this film I thought it was very funny, but it's only after watching it two or three times that you see all the flaws. The acting was OK, but Heather Graham cannot act. Her performance didn't seem very convincing and she wasn't near as good as Liz Hurley was in the first one. Those characters who bloomed in the first one, (Scott Evil, Number 2 etc.) are thrown into the background hear and don't get many stand-alone scenes. The film is simply overrun with cameos.\u003cbr /\u003e\u003cbr /\u003eIn particular, I hated the way they totally disregarded some of the scenes in IMOM. When they killed off Vanessa at the start and had Basil sat that he knew she was a fembot all along. What was the point of that? They killed off Number 2 in the first one, and now they bring him back with no explanation whatsoever. This is supposed to be a spy-spoof, I don't think any of the characters even hold a gun in the film. It just goes on a trail, further and further away from the point.\u003cbr /\u003e\u003cbr /\u003eThe new characters are very unwelcome. The whole Mini-Me `make fun of my size' joke gets old very quickly. Fat Bastard is just a lame excuse for gross-out humour. In total there's about two or three good jokes. The rest are either tasteless or rehashed from IMOM.\u003cbr /\u003e\u003cbr /\u003eIf this were the first movie of the series then I'd probably be easier on it. But the series started on a note of dry wit and then plummeted down to a level of gross out humour. So I say, only watch this film if you haven't seen its predecessor, because The Spy Who Shagged Me is one ultimate disappointment.\""]},"execution_count":17,"metadata":{},"output_type":"execute_result"}],"source":["train_texts[0]"]},{"cell_type":"code","execution_count":18,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":43,"status":"ok","timestamp":1680953000192,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"},"user_tz":-330},"id":"ZhMfofsUhuDL","outputId":"102d7dc4-3f91-49da-c6eb-3d03a65e402b"},"outputs":[{"data":{"text/plain":["0"]},"execution_count":18,"metadata":{},"output_type":"execute_result"}],"source":["train_labels[0]"]},{"cell_type":"markdown","metadata":{"id":"D_ICVBEvikwG"},"source":["## Collect Key Metrics"]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":601,"status":"ok","timestamp":1680960120272,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"},"user_tz":-330},"id":"ngjxklmQB8w9"},"outputs":[],"source":["\"\"\"Module to explore data.\n","Contains functions to help study, visualize and understand datasets.\n","\"\"\"\n","from __future__ import absolute_import\n","from __future__ import division\n","from __future__ import print_function\n","\n","import numpy as np\n","import matplotlib.pyplot as plt\n","\n","from collections import Counter\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","\n","def get_num_classes(labels):\n","    \"\"\"Gets the total number of classes.\n","    # Arguments\n","        labels: list, label values.\n","            There should be at lease one sample for values in the\n","            range (0, num_classes -1)\n","    # Returns\n","        int, total number of classes.\n","    # Raises\n","        ValueError: if any label value in the range(0, num_classes - 1)\n","            is missing or if number of classes is \u003c= 1.\n","    \"\"\"\n","    num_classes = max(labels) + 1\n","    missing_classes = [i for i in range(num_classes) if i not in labels]\n","    if len(missing_classes):\n","        raise ValueError('Missing samples with label value(s) '\n","                         '{missing_classes}. Please make sure you have '\n","                         'at least one sample for every label value '\n","                         'in the range(0, {max_class})'.format(\n","                            missing_classes=missing_classes,\n","                            max_class=num_classes - 1))\n","\n","    if num_classes \u003c= 1:\n","        raise ValueError('Invalid number of labels: {num_classes}.'\n","                         'Please make sure there are at least two classes '\n","                         'of samples'.format(num_classes=num_classes))\n","    return num_classes\n","\n","\n","def get_num_words_per_sample(sample_texts):\n","    \"\"\"Gets the median number of words per sample given corpus.\n","    # Arguments\n","        sample_texts: list, sample texts.\n","    # Returns\n","        int, median number of words per sample.\n","    \"\"\"\n","    num_words = [len(s.split()) for s in sample_texts]\n","    return np.median(num_words)\n","\n","\n","def plot_frequency_distribution_of_ngrams(sample_texts,\n","                                          ngram_range=(1, 2),\n","                                          num_ngrams=50):\n","    \"\"\"Plots the frequency distribution of n-grams.\n","    # Arguments\n","        samples_texts: list, sample texts.\n","        ngram_range: tuple (min, mplt), The range of n-gram values to consider.\n","            Min and mplt are the lower and upper bound values for the range.\n","        num_ngrams: int, number of n-grams to plot.\n","            Top `num_ngrams` frequent n-grams will be plotted.\n","    \"\"\"\n","    # Create args required for vectorizing.\n","    kwargs = {\n","            'ngram_range': (1, 1),\n","            'dtype': 'int32',\n","            'strip_accents': 'unicode',\n","            'decode_error': 'replace',\n","            'analyzer': 'word',  # Split text into word tokens.\n","    }\n","    vectorizer = CountVectorizer(**kwargs)\n","\n","    # This creates a vocabulary (dict, where keys are n-grams and values are\n","    # idxices). This also converts every text to an array the length of\n","    # vocabulary, where every element idxicates the count of the n-gram\n","    # corresponding at that idxex in vocabulary.\n","    vectorized_texts = vectorizer.fit_transform(sample_texts)\n","\n","    # This is the list of all n-grams in the index order from the vocabulary.\n","    all_ngrams = list(vectorizer.get_feature_names())\n","    num_ngrams = min(num_ngrams, len(all_ngrams))\n","    # ngrams = all_ngrams[:num_ngrams]\n","\n","    # Add up the counts per n-gram ie. column-wise\n","    all_counts = vectorized_texts.sum(axis=0).tolist()[0]\n","\n","    # Sort n-grams and counts by frequency and get top `num_ngrams` ngrams.\n","    all_counts, all_ngrams = zip(*[(c, n) for c, n in sorted(\n","        zip(all_counts, all_ngrams), reverse=True)])\n","    ngrams = list(all_ngrams)[:num_ngrams]\n","    counts = list(all_counts)[:num_ngrams]\n","\n","    idx = np.arange(num_ngrams)\n","    plt.bar(idx, counts, width=0.8, color='b')\n","    plt.xlabel('N-grams')\n","    plt.ylabel('Frequencies')\n","    plt.title('Frequency distribution of n-grams')\n","    plt.xticks(idx, ngrams, rotation=45)\n","    plt.show()\n","\n","\n","def plot_sample_length_distribution(sample_texts):\n","    \"\"\"Plots the sample length distribution.\n","    # Arguments\n","        samples_texts: list, sample texts.\n","    \"\"\"\n","    plt.hist([len(s) for s in sample_texts], 50)\n","    plt.xlabel('Length of a sample')\n","    plt.ylabel('Number of samples')\n","    plt.title('Sample length distribution')\n","    plt.show()\n","\n","\n","def plot_class_distribution(labels):\n","    \"\"\"Plots the class distribution.\n","    # Arguments\n","        labels: list, label values.\n","            There should be at lease one sample for values in the\n","            range (0, num_classes -1)\n","    \"\"\"\n","    num_classes = get_num_classes(labels)\n","    count_map = Counter(labels)\n","    counts = [count_map[i] for i in range(num_classes)]\n","    idx = np.arange(num_classes)\n","    plt.bar(idx, counts, width=0.8, color='b')\n","    plt.xlabel('Class')\n","    plt.ylabel('Number of samples')\n","    plt.title('Class distribution')\n","    plt.xticks(idx, idx)\n","    plt.show()"]},{"cell_type":"code","execution_count":19,"metadata":{"executionInfo":{"elapsed":38,"status":"ok","timestamp":1680953000194,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"},"user_tz":-330},"id":"88qjojB-hwQA"},"outputs":[],"source":["def get_num_words_per_sample(sample_texts):\n","  \"\"\"Returns the median number of words per sample given corpus.\n","\n","  # Arguments\n","    sample_texts: list, sample texts.\n","\n","  # Returns\n","    int, median number of words per sample.\n","  \"\"\"\n","  num_words = [len(s.split()) for s in sample_texts]\n","  return np.median(num_words)\n","\n","def plot_sample_length_distributions(sample_texts):\n","  \"\"\"Plots the sample length distribution.\n","\n","  # Arguments\n","    samples_texts: list, sample texts.\n","  \"\"\"\n","  plt.hist([len(s) for s in sample_texts], 50)\n","  plt.xlabel('Length of a sample')\n","  plt.ylabel('Number of samples')\n","  plt.title('Sample length distribution')\n","  plt.show()"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":39,"status":"ok","timestamp":1680953000197,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"},"user_tz":-330},"id":"q3wLo-TpjlQa","outputId":"2c5b751b-8db1-4704-fc93-961c493caad1"},"outputs":[{"data":{"text/plain":["174.0"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["get_num_words_per_sample(train_texts)"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":472},"executionInfo":{"elapsed":734,"status":"ok","timestamp":1680953000899,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"},"user_tz":-330},"id":"nYyKgJWgjrnf","outputId":"1486e4e8-15a5-4d23-e2b4-e9f93e2cc5a6"},"outputs":[{"data":{"image/png":"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\n","text/plain":["\u003cFigure size 640x480 with 1 Axes\u003e"]},"metadata":{},"output_type":"display_data"}],"source":["plot_sample_length_distributions(train_texts)"]},{"cell_type":"markdown","metadata":{"id":"4wBoRxvBZlA0"},"source":["## Prepare Your Data"]},{"cell_type":"markdown","metadata":{"id":"35JLppGYeeCz"},"source":["### N-gram vectors [Option A]"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":29,"status":"ok","timestamp":1680953000901,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"},"user_tz":-330},"id":"Q7dvZthajwD3"},"outputs":[],"source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.feature_selection import SelectKBest\n","from sklearn.feature_selection import f_classif\n","\n","# Vectorization parameters\n","# Range (inclusive) of n-gram sizes for tokenizing text.\n","NGRAM_RANGE = (1, 2)\n","\n","# Limit on the number of features. We use the top 20K features.\n","TOP_K = 20000\n","\n","# Whether text should be split into word or character n-grams.\n","# One of 'word', 'char'.\n","TOKEN_MODE = 'word'\n","\n","# Minimum document/corpus frequency below which a token will be discarded.\n","MINIMUM_DOCUMENT_FREQUENCY = 2\n","\n","def ngram_vectorize(train_texts, train_labels, val_texts):\n","  \"\"\"Vectorize texts as n-gram vectors.\n","\n","  1 text = 1 tf-idf vector the length of vocabulary of unigrams + bigrams\n","\n","  # Arguments\n","      train_texts: list, training text strings.\n","      train_labels: np.ndarray, training labels.\n","      val_texts: list, validation text strings.\n","\n","  # Returns\n","      x_train, x_val: vectorized training and validation texts\n","  \"\"\"\n","  # Create keyword arguments to pass to the 'tf-idf' vectorizer.\n","  kwargs = {\n","      'ngram_range': NGRAM_RANGE, # Use 1-grams + 2-grams.\n","      'dtype': 'int32',\n","      'strip_accents': 'unicode',\n","      'decode_error': 'replace',\n","      'analyzer': TOKEN_MODE, # Split text into word tokens.\n","      'min_df': MINIMUM_DOCUMENT_FREQUENCY,\n","  }\n","  vectorizer = TfidfVectorizer(**kwargs)\n","\n","  # Learn vocabulary from training texts and vectorize training texts.\n","  x_train = vectorizer.fit_transform(train_texts)\n","\n","  # Vectorizer validation texts.\n","  x_val = vectorizer.transform(val_texts)\n","\n","  # Select top 'k' of the vectorized features.\n","  selector = SelectKBest(f_classif, k=min(TOP_K, x_train.shape[1]))\n","  selector.fit(x_train, train_labels)\n","  x_train = selector.transform(x_train).astype('float32')\n","  x_val = selector.transform(x_val).astype('float32')\n","  return x_train, x_val"]},{"cell_type":"markdown","metadata":{"id":"2xX-lNSxizOo"},"source":["### Sequence Vectors [Option B]"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":9,"status":"ok","timestamp":1680953021805,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"},"user_tz":-330},"id":"hbcyZOcld_id"},"outputs":[],"source":["from tensorflow.keras.preprocessing import sequence\n","from tensorflow.keras.preprocessing import text\n","\n","# Vectorization parameters\n","# Limit on the number of features. We use the top 20K features.\n","TOP_K = 20000\n","\n","# Limit on the length of text sequences. Sequence longer than this\n","# will be truncated\n","MAX_SEQUENCE_LENGTH = 500\n","\n","def sequence_vectorize(train_texts, val_texts):\n","  \"\"\"Vectorize texts as sequence vectors.\n","\n","  1 text = 1 sequence vector with fixed length.\n","\n","  # Arguments\n","      train_texts: list, training text strings.\n","      val_texts: list, validation text strings.\n","\n","  # Returns\n","      x_train, x_val, word_index: vectorized training and validation\n","          texts and word index dictionary.\n","  \"\"\"\n","  # Create vocabulary with training texts.\n","  tokenizer = text.Tokenizer(num_words=TOP_K)\n","  tokenizer.fit_on_texts(train_texts)\n","\n","  # Vectorize training and validation texts.\n","  x_train = tokenizer.texts_to_sequences(train_texts)\n","  x_val = tokenizer.texts_to_sequences(val_texts)\n","\n","  # Get max sequence length.\n","  max_length = len(max(x_train, key=len))\n","  if max_length \u003e MAX_SEQUENCE_LENGTH:\n","    max_length = MAX_SEQUENCE_LENGTH\n","\n","  # Fix sequence length to max value. Sequences shorter than the length are \n","  # padded in the beginning and sequences longer are truncated\n","  # at the beginning.\n","  x_train = sequence.pad_sequences(x_train, maxlen=max_length)\n","  x_val = sequence.pad_sequences(x_val, maxlen=max_length)\n","  return x_train, x_val, tokenizer.word_index"]},{"cell_type":"markdown","metadata":{"id":"z8yTbRkftoSd"},"source":["## Constructing the Last Layer"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":3,"status":"ok","timestamp":1680955051534,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"},"user_tz":-330},"id":"wEbGOwNwl1bU"},"outputs":[],"source":["def _get_last_layer_units_and_activation(num_classes):\n","  \"\"\"Gets the # units and activation function for the last network layer.\n","\n","  # Arguments\n","      num_classes: int, number of classes.\n","\n","  # Returns\n","      units, activation values.\n","  \"\"\"\n","  if num_classes == 2:\n","    activation = 'sigmoid'\n","    units = 1\n","  else:\n","    activation = 'softmax'\n","    units = num_classes\n","  return units, activation"]},{"cell_type":"markdown","metadata":{"id":"NonKkJDlvUcU"},"source":["### Build n-gram model [Option A]"]},{"cell_type":"code","execution_count":42,"metadata":{"executionInfo":{"elapsed":1102,"status":"ok","timestamp":1680960520732,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"},"user_tz":-330},"id":"0iX3gWrluVlv"},"outputs":[],"source":["from tensorflow.keras import models\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Dropout\n","\n","def mlp_model(layers, units, dropout_rate, input_shape, num_classes):\n","  \"\"\"Create an instance of a multi-layer perceptron model.\n","\n","  # Arguments\n","      layers: int, number of `Dense` layers in the model.\n","      units: int, output dimension of the layers.\n","      dropout_rate: float, percentage of input to drop at Dropout layers.\n","      input_shape: tuple, shape of input to the model\n","      num_classes: int, number of output classes.\n","\n","  # Returns \n","      An MLP model instance.\n","  \"\"\"\n","  op_units, op_activation = _get_last_layer_units_and_activation(num_classes)\n","  model = models.Sequential()\n","  # model.add(Dropout(rate=dropout_rate, input_shape=input_shape))\n","\n","  for _ in range(layers-1):\n","    model.add(Dense(units=units, activation='relu'))\n","    model.add(Dropout(rate=dropout_rate))\n","\n","  model.add(Dense(units=op_units, activation=op_activation))\n","  return model"]},{"cell_type":"markdown","metadata":{"id":"e4DHiSPcx1hU"},"source":["### Build sequence model [Option B]"]},{"cell_type":"markdown","metadata":{"id":"-TehUuSkzxYT"},"source":["The following code constructs a four-layer sepCNN model:"]},{"cell_type":"code","execution_count":54,"metadata":{"executionInfo":{"elapsed":620,"status":"ok","timestamp":1680960997014,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"},"user_tz":-330},"id":"kcyl-6Sfxx8G"},"outputs":[],"source":["from tensorflow import keras\n","\n","def sepcnn_model(\n","    blocks, \n","    filters,\n","    kernel_size,\n","    embedding_dim,\n","    dropout_rate,\n","    pool_size,\n","    input_shape,\n","    num_classes,\n","    num_features,\n","    use_pretrained_embedding=False,\n","    is_embedding_trainable=False,\n","    embedding_matrix=None):\n","  \"\"\"Createas an instance of a separable CNN model.\n","\n","  # Arguments\n","      blocks: int, number of pairs of sepCNN and pooling blocks in the model.\n","      filters: int, output dimension of the layers.\n","      kernel_size: int, length of the convolutional window.\n","      embedding_dim: int, dimension of the embedding vectors.\n","      dropout_rate: float, percentage of input to drop at Dropout layers.\n","      pool_size: int, factor by which to downscale input at MaxPooling layer.\n","      input_shape: tuple, shape of input to the model.\n","      num_classes: int, number of output classes.\n","      num_features: int, number of words (embedding input dimension).\n","      use_pretrained_embedding: bool, true if pre-trained embedding is on.\n","      is_embedding_trainable: bool, true if embedding layer is trainbale.\n","      embedding_matrix: dict, dictionary with embedding coefficients.\n","  \n","  # Returns\n","      A sepCNN model instance.\n","  \"\"\"\n","  op_units, op_activation = _get_last_layer_units_and_activation(num_classes)\n","  model = keras.models.Sequential()\n","\n","  # Add embedding layer. If pre-trained embedding is used add weights to the\n","  # embeddings layer and set trainable to input is_embedding_trainable flag.\n","  if use_pretrained_embedding:\n","    model.add(keras.layers.Embedding(input_dim=num_features,\n","                                     outpu_dim=embedding_dim,\n","                                     input_length=input_shape[0],\n","                                     weights=[embedding_matrix],\n","                                     trainabel=is_embedding_trainable))\n","  else:\n","    model.add(keras.layers.Embedding(input_dim=num_features,\n","                        output_dim=embedding_dim,\n","                        input_length=input_shape[0]))\n","    \n","  for _ in range(blocks-1):\n","    model.add(Dropout(rate=dropout_rate))\n","    model.add(keras.layers.SeparableConv1D(filters=filters,\n","                                           kernel_size=kernel_size,\n","                                           activation='relu',\n","                                           bias_initializer='random_uniform',\n","\n","                                           padding='same'))\n","    model.add(keras.layers.SeparableConv1D(filters=filters,\n","                                           kernel_size=kernel_size,\n","                                           activation='relu',\n","                                           bias_initializer='random_uniform',\n","                                           padding='same'))\n","    model.add(keras.layers.MaxPooling1D(pool_size=pool_size))\n","\n","  model.add(keras.layers.SeparableConv1D(filters=filters * 2,\n","                                         kernel_size=kernel_size,\n","                                         activation='relu',\n","                                         bias_initializer='random_uniform',\n","                                         padding='same'))\n","  model.add(keras.layers.SeparableConv1D(filters=filters * 2,\n","                                         kernel_size=kernel_size,\n","                                         activation='relu',\n","                                         bias_initializer='random_uniform',\n","                                         padding='same'))\n","  model.add(keras.layers.GlobalAveragePooling1D())\n","  model.add(Dropout(rate=dropout_rate))\n","  model.add(keras.layers.Dense(op_units, activation=op_activation))\n","  return model"]},{"cell_type":"markdown","metadata":{"id":"bKfaT7-K6qrO"},"source":["## Train Your Model"]},{"cell_type":"code","execution_count":44,"metadata":{"executionInfo":{"elapsed":694,"status":"ok","timestamp":1680960632280,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"},"user_tz":-330},"id":"ypKL0SCU5vPl"},"outputs":[],"source":["def train_ngram_model(data, \n","                      learning_rate=1e-3,\n","                      epochs=1000,\n","                      batch_size=128,\n","                      layers=2,\n","                      units=64,\n","                      dropout_rate=0.2):\n","  \"\"\"Trains n-gram model on the given dataset.\n","\n","  # Arguments\n","      data: tuples of training and test texts and labels.\n","      learning_rate: float, learning rate for training model.\n","      epochs: int, number of epochs,\n","      batch_size: int, number of samples per batch.\n","      layers: int, number of `Dense` layers in the model.\n","      units: int, output dimension of Dense layers in the model.\n","      dropout_rate: float, percentage of input to drop at Dropout layers.\n","\n","  # Raises\n","      ValueError: If validation data has label values which were not seen \n","          in the training data.\n","  \"\"\"\n","  # Get the data.\n","  (train_texts, train_labels), (val_texts, val_labels) = data\n","\n","  # Verify that validation labels are in the same range as training labels.\n","  num_classes = get_num_classes(train_labels)\n","  unexpected_labels = [v for v in val_labels if v not in range(num_classes)]\n","  if len(unexpected_labels):\n","      raise ValueError('Unexpected label values found in the validation set:'\n","                        ' {unexpected_labels}. Please make sure that the '\n","                        'labels in the validation set are in the same range '\n","                        'as training labels.'.format(\n","                            unexpected_labels=unexpected_labels))\n","      \n","  # Vectorize texts.\n","  x_train, x_val = ngram_vectorize(\n","      train_texts, train_labels, val_texts)\n","  \n","  # Create model instance.\n","  model = mlp_model(layers=layers,\n","                                units=units,\n","                                dropout_rate=dropout_rate,\n","                                input_shape=x_train.shape[1:],\n","                                num_classes=num_classes)\n","  \n","  # Compile model with learning parameters.\n","  if num_classes == 2:\n","    loss = 'binary_crossentropy'\n","  else:\n","    loss = 'sparse_categorical_crossentropy'\n","  optimizer = keras.optimizers.Adam(learning_rate=learning_rate)\n","  model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n","\n","  # Create callback for early stopping on validation loss. If the loss does\n","  # not decrease in two consecutive tries, stop training.\n","  callbacks = [keras.callbacks.EarlyStopping(\n","      monitor='val_loss', patience=2)]\n","\n","  # Train and validate model.\n","  history = model.fit(\n","      x_train,\n","      train_labels,\n","      epochs=epochs,\n","      callbacks=callbacks,\n","      validation_data=(x_val, val_labels),\n","      verbose=2, # Logs once per epochs.\n","      batch_size=batch_size)\n","  \n","  # Prints results.\n","  history = history.history\n","  print('Validation accuracy: {acc}, loss: {loss}'.format(\n","            acc=history['val_accuracy'][-1], loss=history['val_loss'][-1]))\n","\n","  # Save model.\n","  model.save('IMDb_mlp_model.h5')\n","  return history['val_accuracy'][-1], history['val_loss'][-1]"]},{"cell_type":"code","execution_count":45,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":129271,"status":"ok","timestamp":1680960761535,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"},"user_tz":-330},"id":"XZ0ClziO_XSX","outputId":"32fb57f6-4946-4e99-9c37-df8e4b7303ab"},"outputs":[{"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.9/dist-packages/sklearn/feature_extraction/text.py:2072: UserWarning: Only (\u003cclass 'numpy.float64'\u003e, \u003cclass 'numpy.float32'\u003e, \u003cclass 'numpy.float16'\u003e) 'dtype' should be used. int32 'dtype' will be converted to np.float64.\n","  warnings.warn(\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/1000\n","196/196 - 7s - loss: 0.4637 - accuracy: 0.8627 - val_loss: 0.3159 - val_accuracy: 0.8891 - 7s/epoch - 34ms/step\n","Epoch 2/1000\n","196/196 - 6s - loss: 0.2190 - accuracy: 0.9282 - val_loss: 0.2466 - val_accuracy: 0.9029 - 6s/epoch - 30ms/step\n","Epoch 3/1000\n","196/196 - 6s - loss: 0.1521 - accuracy: 0.9488 - val_loss: 0.2329 - val_accuracy: 0.9048 - 6s/epoch - 32ms/step\n","Epoch 4/1000\n","196/196 - 6s - loss: 0.1163 - accuracy: 0.9630 - val_loss: 0.2300 - val_accuracy: 0.9057 - 6s/epoch - 31ms/step\n","Epoch 5/1000\n","196/196 - 5s - loss: 0.0905 - accuracy: 0.9746 - val_loss: 0.2352 - val_accuracy: 0.9039 - 5s/epoch - 26ms/step\n","Epoch 6/1000\n","196/196 - 6s - loss: 0.0710 - accuracy: 0.9828 - val_loss: 0.2443 - val_accuracy: 0.9016 - 6s/epoch - 28ms/step\n","Validation accuracy: 0.9016000032424927, loss: 0.2443353533744812\n"]},{"data":{"text/plain":["(0.9016000032424927, 0.2443353533744812)"]},"execution_count":45,"metadata":{},"output_type":"execute_result"}],"source":["train_ngram_model(data=((train_texts, train_labels), (test_texts, test_labels)))"]},{"cell_type":"code","execution_count":48,"metadata":{"executionInfo":{"elapsed":901,"status":"ok","timestamp":1680960814413,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"},"user_tz":-330},"id":"4XqrqoJ1Bidp"},"outputs":[],"source":["# Limit on the number of features. We use the top 20K features.\n","TOP_K = 20000\n","\n","\n","def train_sequence_model(data,\n","                         learning_rate=1e-3,\n","                         epochs=1000,\n","                         batch_size=128,\n","                         blocks=2,\n","                         filters=64,\n","                         dropout_rate=0.2,\n","                         embedding_dim=200,\n","                         kernel_size=3,\n","                         pool_size=3):\n","    \"\"\"Trains sequence model on the given dataset.\n","    # Arguments\n","        data: tuples of training and test texts and labels.\n","        learning_rate: float, learning rate for training model.\n","        epochs: int, number of epochs.\n","        batch_size: int, number of samples per batch.\n","        blocks: int, number of pairs of sepCNN and pooling blocks in the model.\n","        filters: int, output dimension of sepCNN layers in the model.\n","        dropout_rate: float: percentage of input to drop at Dropout layers.\n","        embedding_dim: int, dimension of the embedding vectors.\n","        kernel_size: int, length of the convolution window.\n","        pool_size: int, factor by which to downscale input at MaxPooling layer.\n","    # Raises\n","        ValueError: If validation data has label values which were not seen\n","            in the training data.\n","    \"\"\"\n","    # Get the data.\n","    (train_texts, train_labels), (val_texts, val_labels) = data\n","\n","    # Verify that validation labels are in the same range as training labels.\n","    num_classes = get_num_classes(train_labels)\n","    unexpected_labels = [v for v in val_labels if v not in range(num_classes)]\n","    if len(unexpected_labels):\n","        raise ValueError('Unexpected label values found in the validation set:'\n","                         ' {unexpected_labels}. Please make sure that the '\n","                         'labels in the validation set are in the same range '\n","                         'as training labels.'.format(\n","                             unexpected_labels=unexpected_labels))\n","\n","    # Vectorize texts.\n","    x_train, x_val, word_index = sequence_vectorize(\n","            train_texts, val_texts)\n","\n","    # Number of features will be the embedding input dimension. Add 1 for the\n","    # reserved index 0.\n","    num_features = min(len(word_index) + 1, TOP_K)\n","\n","    # Create model instance.\n","    model = sepcnn_model(blocks=blocks,\n","                                     filters=filters,\n","                                     kernel_size=kernel_size,\n","                                     embedding_dim=embedding_dim,\n","                                     dropout_rate=dropout_rate,\n","                                     pool_size=pool_size,\n","                                     input_shape=x_train.shape[1:],\n","                                     num_classes=num_classes,\n","                                     num_features=num_features)\n","\n","    # Compile model with learning parameters.\n","    if num_classes == 2:\n","        loss = 'binary_crossentropy'\n","    else:\n","        loss = 'sparse_categorical_crossentropy'\n","    optimizer = tf.keras.optimizers.Adam(lr=learning_rate)\n","    model.compile(optimizer=optimizer, loss=loss, metrics=['acc'])\n","\n","    # Create callback for early stopping on validation loss. If the loss does\n","    # not decrease in two consecutive tries, stop training.\n","    callbacks = [tf.keras.callbacks.EarlyStopping(\n","        monitor='val_loss', patience=2)]\n","\n","    # Train and validate model.\n","    history = model.fit(\n","            x_train,\n","            train_labels,\n","            epochs=epochs,\n","            callbacks=callbacks,\n","            validation_data=(x_val, val_labels),\n","            verbose=2,  # Logs once per epoch.\n","            batch_size=batch_size)\n","\n","    # Print results.\n","    history = history.history\n","    print('Validation accuracy: {acc}, loss: {loss}'.format(\n","            acc=history['val_accuracy'][-1], loss=history['val_loss'][-1]))\n","\n","    # Save model.\n","    model.save('rotten_tomatoes_sepcnn_model.h5')\n","    return history['val_accuracy'][-1], history['val_loss'][-1]"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"background_save":true,"base_uri":"https://localhost:8080/"},"id":"nwOmyKeOEeTF"},"outputs":[{"name":"stderr","output_type":"stream","text":["WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.Adam.\n"]},{"name":"stdout","output_type":"stream","text":["Epoch 1/1000\n","196/196 - 193s - loss: 0.6934 - acc: 0.4915 - val_loss: 0.6931 - val_acc: 0.5000 - 193s/epoch - 984ms/step\n","Epoch 2/1000\n","196/196 - 190s - loss: 0.6932 - acc: 0.5004 - val_loss: 0.6932 - val_acc: 0.5000 - 190s/epoch - 969ms/step\n","Epoch 3/1000\n","196/196 - 187s - loss: 0.6932 - acc: 0.4996 - val_loss: 0.6932 - val_acc: 0.5000 - 187s/epoch - 954ms/step\n"]},{"ename":"KeyError","evalue":"ignored","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)","\u001b[0;32m\u003cipython-input-55-0da277d4d120\u003e\u001b[0m in \u001b[0;36m\u003ccell line: 1\u003e\u001b[0;34m()\u001b[0m\n\u001b[0;32m----\u003e 1\u001b[0;31m \u001b[0mtrain_sequence_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtest_texts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m\u003cipython-input-48-ea44de1dc8a1\u003e\u001b[0m in \u001b[0;36mtrain_sequence_model\u001b[0;34m(data, learning_rate, epochs, batch_size, blocks, filters, dropout_rate, embedding_dim, kernel_size, pool_size)\u001b[0m\n\u001b[1;32m     87\u001b[0m     \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m     print('Validation accuracy: {acc}, loss: {loss}'.format(\n\u001b[0;32m---\u003e 89\u001b[0;31m             acc=history['val_accuracy'][-1], loss=history['val_loss'][-1]))\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;31m# Save model.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyError\u001b[0m: 'val_accuracy'"]}],"source":["train_sequence_model(data=((train_texts, train_labels), (test_texts, test_labels)))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"9MgnFejBEki-"},"outputs":[],"source":[]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMANOu3Y5E6zAwMb5Or7ZAF","name":"","version":""},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}