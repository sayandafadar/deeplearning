{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyORxGaDEhLIPj6OCv1D8J4i"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"iDaOq8c5P1OH"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"-yUMt2ldPx7E"},"outputs":[],"source":["import io\n","import re\n","import string\n","import tqdm\n","\n","import numpy as np\n","\n","import tensorflow as tf\n","from tensorflow.keras import layers"]},{"cell_type":"code","source":["# Load the TensorBoard notebook extension\n","%load_ext tensorboard"],"metadata":{"id":"GumIWTfRP5Nu"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["SEED = 42\n","AUTOTUNE = tf.data.AUTOTUNE"],"metadata":{"id":"X8I51cIuP6-O"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Vectorize an example sentence"],"metadata":{"id":"7NCHKXeJQHXF"}},{"cell_type":"code","source":["sentence = \"The wide road shimmered in the hot sun\"\n","tokens = list(sentence.lower().split())\n","len(tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"pVkR4vJrP8Md","executionInfo":{"status":"ok","timestamp":1681718863814,"user_tz":-330,"elapsed":1794,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}},"outputId":"a71cdeba-b62c-47cb-d3fc-ec32f0e3b220"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["8"]},"metadata":{},"execution_count":4}]},{"cell_type":"code","source":["vocab, index = {}, 1\n","vocab['<pad>'] = 0\n","for token in tokens:\n","  if token not in vocab:\n","    vocab[token] = index\n","    index += 1\n","vocab_size = len(vocab)\n","vocab"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4xNd4uOgQVjh","executionInfo":{"status":"ok","timestamp":1681719016846,"user_tz":-330,"elapsed":10,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}},"outputId":"7eaae0bd-a1bc-4125-e9bf-ddae0445648d"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'<pad>': 0,\n"," 'the': 1,\n"," 'wide': 2,\n"," 'road': 3,\n"," 'shimmered': 4,\n"," 'in': 5,\n"," 'hot': 6,\n"," 'sun': 7}"]},"metadata":{},"execution_count":5}]},{"cell_type":"code","source":["inverse_vocab = {index: token for token, index in vocab.items()}\n","inverse_vocab"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W32tHNzYQ7cw","executionInfo":{"status":"ok","timestamp":1681719092383,"user_tz":-330,"elapsed":13,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}},"outputId":"203e4c3b-a729-4445-ccec-af7c065c3f02"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{0: '<pad>',\n"," 1: 'the',\n"," 2: 'wide',\n"," 3: 'road',\n"," 4: 'shimmered',\n"," 5: 'in',\n"," 6: 'hot',\n"," 7: 'sun'}"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","source":["example_sequence = [vocab[word] for word in tokens]\n","example_sequence"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DygyTNLmRNFY","executionInfo":{"status":"ok","timestamp":1681719790059,"user_tz":-330,"elapsed":12,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}},"outputId":"c789545a-9590-4e5a-9864-3cc6e9266a53"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[1, 2, 3, 4, 5, 1, 6, 7]"]},"metadata":{},"execution_count":10}]},{"cell_type":"markdown","source":["## Generate skip-grams from one sentence"],"metadata":{"id":"ULgw1INfTk4j"}},{"cell_type":"code","source":["window_size = 2\n","positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n","    example_sequence,\n","    vocabulary_size=vocab_size,\n","    window_size=window_size,\n","    negative_samples=0)\n","len(positive_skip_grams)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2GxOHqFNRdE-","executionInfo":{"status":"ok","timestamp":1681719868038,"user_tz":-330,"elapsed":10,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}},"outputId":"41cb2f32-5ddc-4eea-d5d3-ab365e7cd54b"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["26"]},"metadata":{},"execution_count":11}]},{"cell_type":"code","source":["print(\"(t, c)\")\n","for target, context in positive_skip_grams[:5]:\n","  print(f\"({target}, {context}): ({inverse_vocab[target]}, {inverse_vocab[context]})\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hdcEIpX-ULZu","executionInfo":{"status":"ok","timestamp":1681720097936,"user_tz":-330,"elapsed":727,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}},"outputId":"a4816d53-5617-4bcd-a1f0-8f5f10bf1688"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["(t, c)\n","(6, 5): (hot, in)\n","(2, 4): (wide, shimmered)\n","(5, 6): (in, hot)\n","(1, 3): (the, road)\n","(3, 2): (road, wide)\n"]}]},{"cell_type":"code","source":["# Get target and context words for one positive skip-gram.\n","target_word, context_word = positive_skip_grams[0]\n","\n","# Set the number of negative samples per positive context.\n","num_ns = 4\n","\n","context_class = tf.reshape(tf.constant(context_word, dtype=\"int64\"), (1, 1))\n","negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n","    true_classes=context_class, # class that should be sampled as 'positive'\n","    num_true=1, # each positive skip-gram has 1 positive context class\n","    num_sampled=num_ns, # number of negative context words to sample\n","    unique=True, # all the negative samples should be unique\n","    range_max=vocab_size, # pick index of the samples from [0, vocab_size]\n","    seed=SEED, # seed for reproducibility\n","    name=\"negative_sampling\"    \n",")\n","print(negative_sampling_candidates)\n","print([inverse_vocab[index.numpy()] for index in negative_sampling_candidates])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"cjYm1SmWUxGJ","executionInfo":{"status":"ok","timestamp":1681721664539,"user_tz":-330,"elapsed":13,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}},"outputId":"d87ddd85-93a5-43cc-97a6-870e889fe636"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor([3 6 0 1], shape=(4,), dtype=int64)\n","['road', 'hot', '<pad>', 'the']\n"]}]},{"cell_type":"code","source":["target_word, context_word"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"luzlNqVxX8KT","executionInfo":{"status":"ok","timestamp":1681721664540,"user_tz":-330,"elapsed":11,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}},"outputId":"829f5ae4-da87-4cf5-9376-41cdc68bde60"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(6, 5)"]},"metadata":{},"execution_count":24}]},{"cell_type":"code","source":["context_class"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"7Dp8fhqZaVP4","executionInfo":{"status":"ok","timestamp":1681721664540,"user_tz":-330,"elapsed":7,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}},"outputId":"1a034ba0-cd0d-4bf4-89b4-1462e33c16ff"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.Tensor: shape=(1, 1), dtype=int64, numpy=array([[5]])>"]},"metadata":{},"execution_count":25}]},{"cell_type":"code","source":["# Reduce a dimension so you can use concatenation (in the next step).\n","squeezed_context_class = tf.squeeze(context_class, 1)\n","\n","# Concatenate a positive context word with negative sampled words.\n","context = tf.concat([squeezed_context_class, negative_sampling_candidates], 0)\n","\n","# Label the first context word as `1` (positive) followed by `num_ns` `0`s (negative).\n","label = tf.constant([1] + [0]*num_ns, dtype=\"int64\")\n","target = target_word"],"metadata":{"id":"Rfc_rPKhal4Y","executionInfo":{"status":"ok","timestamp":1681723831533,"user_tz":-330,"elapsed":10,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}}},"execution_count":26,"outputs":[]},{"cell_type":"code","source":["print(f\"target_index    : {target}\")\n","print(f\"target_word     : {inverse_vocab[target_word]}\")\n","print(f\"context_indices : {context}\")\n","print(f\"context_words   : {[inverse_vocab[c.numpy()] for c in context]}\")\n","print(f\"label           : {label}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0-zew-UIjS1a","executionInfo":{"status":"ok","timestamp":1681723857351,"user_tz":-330,"elapsed":19,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}},"outputId":"ff76bae8-f974-44b8-c986-a2a6298e4448"},"execution_count":27,"outputs":[{"output_type":"stream","name":"stdout","text":["target_index    : 6\n","target_word     : hot\n","context_indices : [5 3 6 0 1]\n","context_words   : ['in', 'road', 'hot', '<pad>', 'the']\n","label           : [1 0 0 0 0]\n"]}]},{"cell_type":"code","source":["print(\"target  :\", target)\n","print(\"context :\", context)\n","print(\"label   :\", label)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"65dVmp_KjZUg","executionInfo":{"status":"ok","timestamp":1681723897841,"user_tz":-330,"elapsed":690,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}},"outputId":"b6c94bff-5b82-4603-8599-54fe43bde6d4"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["target  : 6\n","context : tf.Tensor([5 3 6 0 1], shape=(5,), dtype=int64)\n","label   : tf.Tensor([1 0 0 0 0], shape=(5,), dtype=int64)\n"]}]},{"cell_type":"code","source":["sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(size=10)\n","print(sampling_table)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"H0ohkRnijjBg","executionInfo":{"status":"ok","timestamp":1681724220171,"user_tz":-330,"elapsed":465,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}},"outputId":"feab11b3-40a4-48d5-ffbe-f9cc78596b17"},"execution_count":29,"outputs":[{"output_type":"stream","name":"stdout","text":["[0.00315225 0.00315225 0.00547597 0.00741556 0.00912817 0.01068435\n"," 0.01212381 0.01347162 0.01474487 0.0159558 ]\n"]}]},{"cell_type":"code","source":["# Generates skip-gram pairs with negative sampling for a list of sequences\n","# (int-encoded sentences) based on window size, number of negative samples\n","# and vocabulary size.\n","def generate_training_data(sequences, window_size, num_ns, vocab_size, seed):\n","  # Elements of each training example are appended to these lists.\n","  targets, contexts, labels = [], [], []\n","\n","  # Build the sampling table for `vocab_size` tokens.\n","  sampling_table = tf.keras.preprocessing.sequence.make_sampling_table(vocab_size)\n","\n","  # Iterate over all sequences (sentences) in the dataset.\n","  for sequence in tqdm.tqdm(sequences):\n","\n","    # Generate positive skip-gram pairs for a sequence (sentence).\n","    positive_skip_grams, _ = tf.keras.preprocessing.sequence.skipgrams(\n","          sequence,\n","          vocabulary_size=vocab_size,\n","          sampling_table=sampling_table,\n","          window_size=window_size,\n","          negative_samples=0)\n","\n","    # Iterate over each positive skip-gram pair to produce training examples\n","    # with a positive context word and negative samples.\n","    for target_word, context_word in positive_skip_grams:\n","      context_class = tf.expand_dims(\n","          tf.constant([context_word], dtype=\"int64\"), 1)\n","      negative_sampling_candidates, _, _ = tf.random.log_uniform_candidate_sampler(\n","          true_classes=context_class,\n","          num_true=1,\n","          num_sampled=num_ns,\n","          unique=True,\n","          range_max=vocab_size,\n","          seed=seed,\n","          name=\"negative_sampling\")\n","\n","      # Build context and label vectors (for one target word)\n","      context = tf.concat([tf.squeeze(context_class,1), negative_sampling_candidates], 0)\n","      label = tf.constant([1] + [0]*num_ns, dtype=\"int64\")\n","\n","      # Append each element from the training example to global lists.\n","      targets.append(target_word)\n","      contexts.append(context)\n","      labels.append(label)\n","\n","  return targets, contexts, labels"],"metadata":{"id":"lm1rZ_dkkx2u","executionInfo":{"status":"ok","timestamp":1681724376472,"user_tz":-330,"elapsed":9,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}}},"execution_count":30,"outputs":[]},{"cell_type":"code","source":["path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0D6QpypnlYG2","executionInfo":{"status":"ok","timestamp":1681724434511,"user_tz":-330,"elapsed":22,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}},"outputId":"e2586c99-7aef-44d3-caba-0f4e2657ae56"},"execution_count":31,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt\n","1115394/1115394 [==============================] - 0s 0us/step\n"]}]},{"cell_type":"code","source":["with open(path_to_file) as f:\n","  lines = f.read().splitlines()\n","for line in lines[:20]:\n","  print(line)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"r3LeVouXllnd","executionInfo":{"status":"ok","timestamp":1681724451421,"user_tz":-330,"elapsed":430,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}},"outputId":"b5b4c621-8520-4a92-c3d3-adc31788dfe0"},"execution_count":32,"outputs":[{"output_type":"stream","name":"stdout","text":["First Citizen:\n","Before we proceed any further, hear me speak.\n","\n","All:\n","Speak, speak.\n","\n","First Citizen:\n","You are all resolved rather to die than to famish?\n","\n","All:\n","Resolved. resolved.\n","\n","First Citizen:\n","First, you know Caius Marcius is chief enemy to the people.\n","\n","All:\n","We know't, we know't.\n","\n","First Citizen:\n","Let us kill him, and we'll have corn at our own price.\n"]}]},{"cell_type":"code","source":["text_ds = tf.data.TextLineDataset(path_to_file).filter(lambda x: tf.cast(tf.strings.length(x), bool))"],"metadata":{"id":"RMCBkcWblqOt","executionInfo":{"status":"ok","timestamp":1681724500266,"user_tz":-330,"elapsed":425,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["# Now, create a custom standardization function to lowercase the text and\n","# remove punctuation.\n","def custom_standardization(input_data):\n","  lowercase = tf.strings.lower(input_data)\n","  return tf.strings.regex_replace(lowercase,\n","                                  '[%s]' % re.escape(string.punctuation), '')\n","\n","\n","# Define the vocabulary size and the number of words in a sequence.\n","vocab_size = 4096\n","sequence_length = 10\n","\n","# Use the `TextVectorization` layer to normalize, split, and map strings to\n","# integers. Set the `output_sequence_length` length to pad all samples to the\n","# same length.\n","vectorize_layer = layers.TextVectorization(\n","    standardize=custom_standardization,\n","    max_tokens=vocab_size,\n","    output_mode='int',\n","    output_sequence_length=sequence_length)"],"metadata":{"id":"CVIs1PEgmBn0","executionInfo":{"status":"ok","timestamp":1681724548578,"user_tz":-330,"elapsed":6,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}}},"execution_count":34,"outputs":[]},{"cell_type":"code","source":["vectorize_layer.adapt(text_ds.batch(1024))"],"metadata":{"id":"_SyrPZsQmB7D","executionInfo":{"status":"ok","timestamp":1681724560351,"user_tz":-330,"elapsed":1641,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["# Save the created vocabulary for reference.\n","inverse_vocab = vectorize_layer.get_vocabulary()\n","print(inverse_vocab[:20])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zj8kMcBomEh3","executionInfo":{"status":"ok","timestamp":1681724566903,"user_tz":-330,"elapsed":11,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}},"outputId":"8dd223a3-9e70-48e3-e635-7bc6432010d4"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["['', '[UNK]', 'the', 'and', 'to', 'i', 'of', 'you', 'my', 'a', 'that', 'in', 'is', 'not', 'for', 'with', 'me', 'it', 'be', 'your']\n"]}]},{"cell_type":"code","source":["# Vectorize the data in text_ds.\n","text_vector_ds = text_ds.batch(1024).prefetch(AUTOTUNE).map(vectorize_layer).unbatch()"],"metadata":{"id":"BUzJAy1VmGj1","executionInfo":{"status":"ok","timestamp":1681724585471,"user_tz":-330,"elapsed":6,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["sequences = list(text_vector_ds.as_numpy_iterator())\n","print(len(sequences))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"2m4IQ8sNmLHt","executionInfo":{"status":"ok","timestamp":1681724632720,"user_tz":-330,"elapsed":11035,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}},"outputId":"ce690db9-5c13-48e8-9149-1ecf9a61bd10"},"execution_count":38,"outputs":[{"output_type":"stream","name":"stdout","text":["32777\n"]}]},{"cell_type":"code","source":["for seq in sequences[:5]:\n","  print(f\"{seq} => {[inverse_vocab[i] for i in seq]}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"kYQvnL9vmT5N","executionInfo":{"status":"ok","timestamp":1681724632722,"user_tz":-330,"elapsed":56,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}},"outputId":"2f99507a-6a10-4699-b424-0a60bf307cf1"},"execution_count":39,"outputs":[{"output_type":"stream","name":"stdout","text":["[ 89 270   0   0   0   0   0   0   0   0] => ['first', 'citizen', '', '', '', '', '', '', '', '']\n","[138  36 982 144 673 125  16 106   0   0] => ['before', 'we', 'proceed', 'any', 'further', 'hear', 'me', 'speak', '', '']\n","[34  0  0  0  0  0  0  0  0  0] => ['all', '', '', '', '', '', '', '', '', '']\n","[106 106   0   0   0   0   0   0   0   0] => ['speak', 'speak', '', '', '', '', '', '', '', '']\n","[ 89 270   0   0   0   0   0   0   0   0] => ['first', 'citizen', '', '', '', '', '', '', '', '']\n"]}]},{"cell_type":"code","source":["targets, contexts, labels = generate_training_data(\n","    sequences=sequences,\n","    window_size=2,\n","    num_ns=4,\n","    vocab_size=vocab_size,\n","    seed=SEED)\n","\n","targets = np.array(targets)\n","contexts = np.array(contexts)\n","labels = np.array(labels)\n","\n","print('\\n')\n","print(f\"targets.shape: {targets.shape}\")\n","print(f\"contexts.shape: {contexts.shape}\")\n","print(f\"labels.shape: {labels.shape}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JCyfWRKkmVx9","executionInfo":{"status":"ok","timestamp":1681724681878,"user_tz":-330,"elapsed":23844,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}},"outputId":"e4681a14-710b-4b0a-ecfb-b350e67fa5b7"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stderr","text":["100%|██████████| 32777/32777 [00:22<00:00, 1462.27it/s]\n"]},{"output_type":"stream","name":"stdout","text":["\n","\n","targets.shape: (65157,)\n","contexts.shape: (65157, 5)\n","labels.shape: (65157, 5)\n"]}]},{"cell_type":"code","source":["BATCH_SIZE = 1024\n","BUFFER_SIZE = 10000\n","dataset = tf.data.Dataset.from_tensor_slices(((targets, contexts), labels))\n","dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n","print(dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_SFVslvxmcy9","executionInfo":{"status":"ok","timestamp":1681724686562,"user_tz":-330,"elapsed":15,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}},"outputId":"e0442141-49dd-46a8-a144-a1af05ad2be6"},"execution_count":41,"outputs":[{"output_type":"stream","name":"stdout","text":["<_BatchDataset element_spec=((TensorSpec(shape=(1024,), dtype=tf.int64, name=None), TensorSpec(shape=(1024, 5), dtype=tf.int64, name=None)), TensorSpec(shape=(1024, 5), dtype=tf.int64, name=None))>\n"]}]},{"cell_type":"code","source":["dataset = dataset.cache().prefetch(buffer_size=AUTOTUNE)\n","print(dataset)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t9RouRdemjzs","executionInfo":{"status":"ok","timestamp":1681724694707,"user_tz":-330,"elapsed":520,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}},"outputId":"1ea6bed1-f551-4115-b831-c5257140929c"},"execution_count":42,"outputs":[{"output_type":"stream","name":"stdout","text":["<_PrefetchDataset element_spec=((TensorSpec(shape=(1024,), dtype=tf.int64, name=None), TensorSpec(shape=(1024, 5), dtype=tf.int64, name=None)), TensorSpec(shape=(1024, 5), dtype=tf.int64, name=None))>\n"]}]},{"cell_type":"code","source":["class Word2Vec(tf.keras.Model):\n","  def __init__(self, vocab_size, embedding_dim):\n","    super(Word2Vec, self).__init__()\n","    self.target_embedding = layers.Embedding(vocab_size,\n","                                      embedding_dim,\n","                                      input_length=1,\n","                                      name=\"w2v_embedding\")\n","    self.context_embedding = layers.Embedding(vocab_size,\n","                                       embedding_dim,\n","                                       input_length=num_ns+1)\n","\n","  def call(self, pair):\n","    target, context = pair\n","    # target: (batch, dummy?)  # The dummy axis doesn't exist in TF2.7+\n","    # context: (batch, context)\n","    if len(target.shape) == 2:\n","      target = tf.squeeze(target, axis=1)\n","    # target: (batch,)\n","    word_emb = self.target_embedding(target)\n","    # word_emb: (batch, embed)\n","    context_emb = self.context_embedding(context)\n","    # context_emb: (batch, context, embed)\n","    dots = tf.einsum('be,bce->bc', word_emb, context_emb)\n","    # dots: (batch, context)\n","    return dots"],"metadata":{"id":"O0TJtz0Wmlv0","executionInfo":{"status":"ok","timestamp":1681724739997,"user_tz":-330,"elapsed":592,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["def custom_loss(x_logit, y_true):\n","      return tf.nn.sigmoid_cross_entropy_with_logits(logits=x_logit, labels=y_true)"],"metadata":{"id":"Xvk7Qa7-mwzh","executionInfo":{"status":"ok","timestamp":1681724749790,"user_tz":-330,"elapsed":8,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}}},"execution_count":44,"outputs":[]},{"cell_type":"code","source":["embedding_dim = 128\n","word2vec = Word2Vec(vocab_size, embedding_dim)\n","word2vec.compile(optimizer='adam',\n","                 loss=tf.keras.losses.CategoricalCrossentropy(from_logits=True),\n","                 metrics=['accuracy'])"],"metadata":{"id":"aRFVprGymy9x","executionInfo":{"status":"ok","timestamp":1681724755933,"user_tz":-330,"elapsed":9,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}}},"execution_count":45,"outputs":[]},{"cell_type":"code","source":["tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=\"logs\")"],"metadata":{"id":"Vj3RKS83m0sB","executionInfo":{"status":"ok","timestamp":1681724766033,"user_tz":-330,"elapsed":431,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}}},"execution_count":46,"outputs":[]},{"cell_type":"code","source":["word2vec.fit(dataset, epochs=20, callbacks=[tensorboard_callback])"],"metadata":{"id":"3I95cnmLm3II","executionInfo":{"status":"ok","timestamp":1681724786295,"user_tz":-330,"elapsed":15112,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}},"outputId":"b1fbb2e7-c599-4ae8-9142-ad204d201a86","colab":{"base_uri":"https://localhost:8080/"}},"execution_count":47,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/20\n","63/63 [==============================] - 2s 16ms/step - loss: 1.6083 - accuracy: 0.2328\n","Epoch 2/20\n","63/63 [==============================] - 1s 10ms/step - loss: 1.5892 - accuracy: 0.5496\n","Epoch 3/20\n","63/63 [==============================] - 1s 9ms/step - loss: 1.5422 - accuracy: 0.6039\n","Epoch 4/20\n","63/63 [==============================] - 1s 10ms/step - loss: 1.4593 - accuracy: 0.5780\n","Epoch 5/20\n","63/63 [==============================] - 1s 9ms/step - loss: 1.3605 - accuracy: 0.5838\n","Epoch 6/20\n","63/63 [==============================] - 1s 10ms/step - loss: 1.2636 - accuracy: 0.6083\n","Epoch 7/20\n","63/63 [==============================] - 1s 9ms/step - loss: 1.1738 - accuracy: 0.6414\n","Epoch 8/20\n","63/63 [==============================] - 1s 10ms/step - loss: 1.0906 - accuracy: 0.6749\n","Epoch 9/20\n","63/63 [==============================] - 1s 13ms/step - loss: 1.0132 - accuracy: 0.7056\n","Epoch 10/20\n","63/63 [==============================] - 1s 13ms/step - loss: 0.9412 - accuracy: 0.7356\n","Epoch 11/20\n","63/63 [==============================] - 1s 9ms/step - loss: 0.8743 - accuracy: 0.7615\n","Epoch 12/20\n","63/63 [==============================] - 1s 9ms/step - loss: 0.8124 - accuracy: 0.7839\n","Epoch 13/20\n","63/63 [==============================] - 1s 9ms/step - loss: 0.7553 - accuracy: 0.8035\n","Epoch 14/20\n","63/63 [==============================] - 1s 10ms/step - loss: 0.7030 - accuracy: 0.8202\n","Epoch 15/20\n","63/63 [==============================] - 1s 10ms/step - loss: 0.6550 - accuracy: 0.8353\n","Epoch 16/20\n","63/63 [==============================] - 1s 10ms/step - loss: 0.6112 - accuracy: 0.8497\n","Epoch 17/20\n","63/63 [==============================] - 1s 10ms/step - loss: 0.5713 - accuracy: 0.8620\n","Epoch 18/20\n","63/63 [==============================] - 1s 10ms/step - loss: 0.5350 - accuracy: 0.8729\n","Epoch 19/20\n","63/63 [==============================] - 1s 9ms/step - loss: 0.5020 - accuracy: 0.8825\n","Epoch 20/20\n","63/63 [==============================] - 1s 10ms/step - loss: 0.4719 - accuracy: 0.8918\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7ff76cb329d0>"]},"metadata":{},"execution_count":47}]},{"cell_type":"code","source":[],"metadata":{"id":"lYuCcwAwm4Ro"},"execution_count":null,"outputs":[]}]}