{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyO1aVVO+BaBmWyZldb9zXxA"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"markdown","source":["# Setup"],"metadata":{"id":"PhpPiapPAtfT"}},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"5nNIyZNf-tkW","executionInfo":{"status":"ok","timestamp":1682246747451,"user_tz":-330,"elapsed":12801,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}},"outputId":"d570370c-b102-477c-bcf3-00d703434b21"},"outputs":[{"output_type":"stream","name":"stdout","text":["Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting tensorflow-text>=2.11\n","  Downloading tensorflow_text-2.12.1-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m68.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tensorflow<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow-text>=2.11) (2.12.0)\n","Requirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow-text>=2.11) (0.13.0)\n","Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (0.2.0)\n","Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (3.8.0)\n","Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (0.32.0)\n","Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (2.12.0)\n","Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (0.4.8)\n","Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (3.20.3)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (67.6.1)\n","Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (23.3.3)\n","Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (0.4.0)\n","Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (1.14.1)\n","Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (2.12.0)\n","Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (1.6.3)\n","Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (2.12.2)\n","Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (1.22.4)\n","Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (1.16.0)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (3.3.0)\n","Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (16.0.0)\n","Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (1.4.0)\n","Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (1.53.0)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (23.1)\n","Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (4.5.0)\n","Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.9/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (2.2.0)\n","Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.9/dist-packages (from astunparse>=1.6.0->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (0.40.0)\n","Requirement already satisfied: ml-dtypes>=0.0.3 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.15->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (0.1.0)\n","Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.9/dist-packages (from jax>=0.3.15->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (1.10.1)\n","Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (2.27.1)\n","Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (1.8.1)\n","Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (0.7.0)\n","Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (2.2.3)\n","Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (3.4.3)\n","Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (1.0.0)\n","Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.9/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (2.17.3)\n","Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (5.3.0)\n","Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (4.9)\n","Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.9/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (0.2.8)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.9/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (1.3.1)\n","Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.9/dist-packages (from markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (6.4.1)\n","Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (2.0.12)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (2022.12.7)\n","Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (1.26.15)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.9/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (3.4)\n","Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.9/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (2.1.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.9/dist-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (3.15.0)\n","Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.9/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (0.4.8)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.9/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text>=2.11) (3.2.2)\n","Installing collected packages: tensorflow-text\n","Successfully installed tensorflow-text-2.12.1\n","Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n","Collecting einops\n","  Downloading einops-0.6.1-py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: einops\n","Successfully installed einops-0.6.1\n"]}],"source":["!pip install \"tensorflow-text>=2.11\"\n","!pip install einops"]},{"cell_type":"code","source":["import numpy as np\n","\n","import typing\n","from typing import Any, Tuple\n","\n","import einops\n","import matplotlib.pyplot as plt\n","import matplotlib.ticker as ticker\n","\n","import tensorflow as tf\n","import tensorflow_text as tf_text"],"metadata":{"id":"8wtcovXpA0Vu","executionInfo":{"status":"ok","timestamp":1682246749672,"user_tz":-330,"elapsed":2237,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}}},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":["This tutorial uses a lot of low level API's where it's easy to get shapes wrong. This class is used to check shapes throughout the tutorial."],"metadata":{"id":"ylI57e3PBRXU"}},{"cell_type":"code","source":["class ShapeChecker():\n","  def __init__(self):\n","    self.shapes = {}\n","\n","  def __call__(self, tensor, names, broadcast=False):\n","    if not tf.executing_eagerly():\n","      return\n","\n","    parsed = einops.parse_shape(tensor, names)\n","\n","    for name, new_dim in parsed.items():\n","      old_dim = self.shapes.get(name, None)\n","\n","      if (broadcast and new_dim == 1):\n","        continue\n","\n","      if old_dim is None:\n","        # If axis name is new, add its length to the cache.\n","        self.shapes[name] = new_dim\n","        continue\n","\n","      if new_dim != old_dim:\n","        raise ValueError(f\"Shape mismatch for dimension: '{name}'\\n\"\n","                         f\"    found: {new_dim}\\n\"\n","                         f\"    expected: {old_dim}\\n\")"],"metadata":{"id":"xbu3JF-XBK91","executionInfo":{"status":"ok","timestamp":1682246749674,"user_tz":-330,"elapsed":23,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}}},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":["# The data"],"metadata":{"id":"V6kmcPKWDcsm"}},{"cell_type":"markdown","source":["## Download and prepare the dataset"],"metadata":{"id":"vh1zbAxTDl06"}},{"cell_type":"code","source":["import pathlib\n","\n","path_to_zip = tf.keras.utils.get_file(\n","    'spa-eng.zip', origin='http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip',\n","    extract=True)\n","\n","path_to_file = pathlib.Path(path_to_zip).parent/'spa-eng/spa.txt'"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QAQ63kGWCWr0","executionInfo":{"status":"ok","timestamp":1682246751890,"user_tz":-330,"elapsed":2234,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}},"outputId":"4a1238ba-8d9d-4b9c-902d-502ac20bfbdf"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Downloading data from http://storage.googleapis.com/download.tensorflow.org/data/spa-eng.zip\n","2638744/2638744 [==============================] - 1s 0us/step\n"]}]},{"cell_type":"code","source":["def load_data(path):\n","  text = path.read_text(encoding='utf-8')\n","\n","  lines = text.splitlines()\n","  pairs = [line.split('\\t') for line in lines]\n","\n","  context = np.array([context for target, context in pairs])\n","  target = np.array([target for target, context in pairs])\n","\n","  return target, context"],"metadata":{"id":"uwkj0lU0EGUe","executionInfo":{"status":"ok","timestamp":1682246751891,"user_tz":-330,"elapsed":61,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["target_raw, context_raw = load_data(path_to_file)\n","print(context_raw[-1])\n","print(target_raw[-1])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0ND72wELFIvj","executionInfo":{"status":"ok","timestamp":1682246751893,"user_tz":-330,"elapsed":61,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}},"outputId":"4b759a5c-e8ac-43d5-ffff-fa9b35b1debf"},"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Si quieres sonar como un hablante nativo, debes estar dispuesto a practicar diciendo la misma frase una y otra vez de la misma manera en que un músico de banjo practica el mismo fraseo una y otra vez hasta que lo puedan tocar correctamente y en el tiempo esperado.\n","If you want to sound like a native speaker, you must be willing to practice saying the same sentence over and over in the same way that banjo players practice the same phrase over and over until they can play it correctly and at the desired tempo.\n"]}]},{"cell_type":"markdown","source":["## Create a tf.data dataset"],"metadata":{"id":"EjkQQjSwF0HW"}},{"cell_type":"code","source":["BUFFER_SIZE = len(context_raw)\n","BATCH_SIZE = 64\n","\n","is_train = np.random.uniform(size=(len(target_raw),)) < 0.8\n","\n","train_raw = (\n","    tf.data.Dataset\n","    .from_tensor_slices((context_raw[is_train], target_raw[is_train]))\n","    .shuffle(BUFFER_SIZE)\n","    .batch(BATCH_SIZE))\n","val_raw = (\n","    tf.data.Dataset\n","    .from_tensor_slices((context_raw[~is_train], target_raw[~is_train]))\n","    .shuffle(BUFFER_SIZE)\n","    .batch(BATCH_SIZE))"],"metadata":{"id":"MTgEUkGqFb5o","executionInfo":{"status":"ok","timestamp":1682246756082,"user_tz":-330,"elapsed":4243,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}}},"execution_count":7,"outputs":[]},{"cell_type":"code","source":["for example_context_strings, example_target_strings in train_raw.take(1):\n","  print(example_context_strings[:5])\n","  print()\n","  print(example_target_strings[:5])\n","  break"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"200_ebggHUbU","executionInfo":{"status":"ok","timestamp":1682246762362,"user_tz":-330,"elapsed":46,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}},"outputId":"67a93c87-d858-4a02-8cf1-b1b0790157c0"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["tf.Tensor(\n","[b'Tom es una persona muy extrovertida.'\n"," b'\\xc2\\xbfCu\\xc3\\xa1l metro va al centro?' b'Ponte una bata.'\n"," b'Eres lo mejor que me haya pasado.'\n"," b'Su vida estuvo llena de altos y bajos.'], shape=(5,), dtype=string)\n","\n","tf.Tensor(\n","[b'Tom is a very outgoing person.'\n"," b'What subway goes to the center of town?' b'Put on a robe.'\n"," b\"You're the best thing that ever happened to me.\"\n"," b'His life was full of ups and downs.'], shape=(5,), dtype=string)\n"]}]},{"cell_type":"markdown","source":["## Text preprocessing"],"metadata":{"id":"CnAto92sIcMN"}},{"cell_type":"markdown","source":["**Standardization**\n","\n","The model is dealing with multilingual text with a limited vocabulary. So it will be important to standardize the input text.\n","\n","The first step is Unicode normalization to split accented characters and replace compatibility characters with their ASCII equivalents.\n","\n","The `tensorflow_text` package contains a unicode normalize operation:"],"metadata":{"id":"qc-6xxHNI7kO"}},{"cell_type":"code","source":["example_text = tf.constant('¿Todavía está en casa?')\n","\n","print(example_text.numpy())\n","print(tf_text.normalize_utf8(example_text, 'NFKD').numpy())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WAqJv6nTIQRO","executionInfo":{"status":"ok","timestamp":1682246942896,"user_tz":-330,"elapsed":15,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}},"outputId":"2b8f5f2e-654e-460e-b7f2-31d643bc4fb1"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["b'\\xc2\\xbfTodav\\xc3\\xada est\\xc3\\xa1 en casa?'\n","b'\\xc2\\xbfTodavi\\xcc\\x81a esta\\xcc\\x81 en casa?'\n"]}]},{"cell_type":"code","source":["def tf_lower_and_split_punct(text):\n","  text = tf_text.normalize_utf8(text, 'NFKD')\n","  text = tf.strings.lower(text)\n","  text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n","  text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n","  text = tf.strings.strip(text)\n","\n","  text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n","  return text"],"metadata":{"id":"zddmhzBPJGmV","executionInfo":{"status":"ok","timestamp":1682246942899,"user_tz":-330,"elapsed":11,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["print(example_text.numpy().decode())\n","print(tf_lower_and_split_punct(example_text).numpy().decode())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qMzB9I7jKdj4","executionInfo":{"status":"ok","timestamp":1682247008687,"user_tz":-330,"elapsed":9,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}},"outputId":"38730f1a-5837-45ae-b239-ea36804897ef"},"execution_count":13,"outputs":[{"output_type":"stream","name":"stdout","text":["¿Todavía está en casa?\n","[START] ¿ todavia esta en casa ? [END]\n"]}]},{"cell_type":"markdown","source":["**Spanish TextVectorization**"],"metadata":{"id":"CELet-47LwYD"}},{"cell_type":"code","source":["max_vocab_size = 5000\n","\n","context_text_processor = tf.keras.layers.TextVectorization(\n","    standardize=tf_lower_and_split_punct,\n","    max_tokens=max_vocab_size,\n","    ragged=True)"],"metadata":{"id":"fDCXU0OLKjB8","executionInfo":{"status":"ok","timestamp":1682247061759,"user_tz":-330,"elapsed":685,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["context_text_processor.adapt(train_raw.map(lambda context, target: context))\n","\n","print(\"First 10 words from the vocabulary\")\n","context_text_processor.get_vocabulary()[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RxuirialLHzw","executionInfo":{"status":"ok","timestamp":1682247070104,"user_tz":-330,"elapsed":5489,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}},"outputId":"486162e7-9d16-4c62-8369-ed319ea0ee56"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["First 10 words from the vocabulary\n"]},{"output_type":"execute_result","data":{"text/plain":["['', '[UNK]', '[START]', '[END]', '.', 'que', 'de', 'el', 'a', 'no']"]},"metadata":{},"execution_count":15}]},{"cell_type":"markdown","source":["**English TextVectorization**"],"metadata":{"id":"unskS9DhL1vY"}},{"cell_type":"code","source":["target_text_processor = tf.keras.layers.TextVectorization(\n","    standardize=tf_lower_and_split_punct,\n","    max_tokens=max_vocab_size,\n","    ragged=True)\n","\n","target_text_processor.adapt(train_raw.map(lambda context, target: target))\n","print(\"First 10 words from the vocabulary\")\n","target_text_processor.get_vocabulary()[:10]"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t_Ad1-e1LqPz","executionInfo":{"status":"ok","timestamp":1682247164906,"user_tz":-330,"elapsed":3583,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}},"outputId":"28547519-df5b-4d64-da9f-cfc463d2d98d"},"execution_count":16,"outputs":[{"output_type":"stream","name":"stdout","text":["First 10 words from the vocabulary\n"]},{"output_type":"execute_result","data":{"text/plain":["['', '[UNK]', '[START]', '[END]', '.', 'the', 'i', 'to', 'you', 'tom']"]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["example_tokens = context_text_processor(example_context_strings)\n","example_tokens[:3, :]"],"metadata":{"id":"rDh_YAbSMYM6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1682247170997,"user_tz":-330,"elapsed":900,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}},"outputId":"40ed1fd0-b765-4d44-f9d3-a9311c89de6a"},"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<tf.RaggedTensor [[2, 10, 15, 23, 229, 42, 1, 4, 3],\n"," [2, 13, 154, 1707, 117, 37, 1562, 12, 3], [2, 2048, 23, 1, 4, 3]]>"]},"metadata":{},"execution_count":17}]},{"cell_type":"code","source":["context_vocab = np.array(context_text_processor.get_vocabulary())\n","tokens = context_vocab[example_tokens[0].numpy()]\n","' '.join(tokens)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":36},"id":"DIeDNey9V6AG","executionInfo":{"status":"ok","timestamp":1682247237011,"user_tz":-330,"elapsed":22,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}},"outputId":"62237a6a-4c4b-4333-9ce4-102092339223"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'[START] tom es una persona muy [UNK] . [END]'"],"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"}},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["plt.subplot(1, 2, 1)\n","plt.pcolormesh(example_tokens.to_tensor())\n","plt.title('Token IDs')\n","\n","plt.subplot(1, 2, 2)\n","plt.pcolormesh(example_tokens.to_tensor() != 0)\n","plt.title('Mask')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":469},"id":"cIrVxz2uWiL-","executionInfo":{"status":"ok","timestamp":1682247234051,"user_tz":-330,"elapsed":713,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}},"outputId":"ba6ce26d-5b05-4e0c-abc4-4a2b0a7fc972"},"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Text(0.5, 1.0, 'Mask')"]},"metadata":{},"execution_count":18},{"output_type":"display_data","data":{"text/plain":["<Figure size 640x480 with 2 Axes>"],"image/png":"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\n"},"metadata":{}}]},{"cell_type":"markdown","source":["## Process the dataset\n","\n","The `process_text` function below converts the `Datasets` of strings, into 0-padded tenors of token IDs. It also converts from a (`context, target`) pair to an ((`context, tagret_in), target_out`) pair for training with `keras.Model.fit`. Keras expects (`inputs, labels`) pairs, the inputs are the (`context, target_in`) and the labels are `target_out`. The difference between `target_in` and `target_out` is that they are shifted by one step relative to each other, so that at each location the label is the next token."],"metadata":{"id":"FOwc7K86X6sH"}},{"cell_type":"code","source":["def process_text(context, target):\n","  context = context_text_processor(context).to_tensor()\n","  target = target_text_processor(target)\n","  targ_in = target[:, :-1].to_tensor()\n","  targ_out = target[:, 1:].to_tensor()\n","  return (context, targ_in), targ_out\n","\n","train_ds = train_raw.map(process_text, tf.data.AUTOTUNE)\n","val_ds = val_raw.map(process_text, tf.data.AUTOTUNE)"],"metadata":{"id":"HUPdRBddXMUN","executionInfo":{"status":"ok","timestamp":1682247325662,"user_tz":-330,"elapsed":803,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["for (ex_context_tok, ex_tar_in), ex_tar_out in train_ds.take(1):\n","  print(ex_context_tok[0, :10].numpy()) \n","  print()\n","  print(ex_tar_in[0, :10].numpy()) \n","  print(ex_tar_out[0, :10].numpy())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aGsupmtHZ6au","executionInfo":{"status":"ok","timestamp":1682247366337,"user_tz":-330,"elapsed":13,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}},"outputId":"d634b2a4-f404-4677-bd5c-cf82793f4284"},"execution_count":21,"outputs":[{"output_type":"stream","name":"stdout","text":["[   2    7 4522   27 4387   34 1792   22    5  803]\n","\n","[   2   13 3557  678   29  238    4    0    0    0]\n","[  13 3557  678   29  238    4    3    0    0    0]\n"]}]},{"cell_type":"code","source":["UNITS = 256"],"metadata":{"id":"MYPd9Um5aLAA","executionInfo":{"status":"ok","timestamp":1682247386713,"user_tz":-330,"elapsed":625,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}}},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":["## The encoder\n","The goal of the encoder is to process the context sequence into a sequence of vectors that are useful for are useful for the decoder as it attempts to predict the next output for rach timestep. Since the context sequence is constant, there is no restriction on how information can flow in the encoder, so use a bidirectional-RNN to do the processing:"],"metadata":{"id":"AsvE0MkOb1wA"}},{"cell_type":"code","source":["class Encoder(tf.keras.layers.Layer):\n","  def __init__(self, text_processor, units):\n","    super(Encoder, self).__init__()\n","    self.text_processor = text_processor\n","    self.vocab_size = text_processor.vocabulary_size()\n","    self.units = units\n","\n","    # The embedding layer converts tokens to vectors\n","    self.embedding = tf.keras.layers.Embedding(self.vocab_size, units,\n","                                               mask_zero=True)\n","\n","    # The RNN layer processes those vectors sequentially.\n","    self.rnn = tf.keras.layers.Bidirectional(\n","        merge_mode='sum',\n","        layer=tf.keras.layers.GRU(units,\n","                            # Return the sequence and state\n","                            return_sequences=True,\n","                            recurrent_initializer='glorot_uniform'))\n","\n","  def call(self, x):\n","    shape_checker = ShapeChecker()\n","    shape_checker(x, 'batch s')\n","\n","    # 2. The embedding layer looks up the embedding vector for each token.\n","    x = self.embedding(x)\n","    shape_checker(x, 'batch s units')\n","\n","    # 3. The GRU processes the sequence of embeddings.\n","    x = self.rnn(x)\n","    shape_checker(x, 'batch s units')\n","\n","    # 4. Returns the new sequence of embeddings.\n","    return x\n","\n","  def convert_input(self, texts):\n","    texts = tf.convert_to_tensor(texts)\n","    if len(texts.shape) == 0:\n","      texts = tf.convert_to_tensor(texts)[tf.newaxis]\n","    context = self.text_processor(texts).to_tensor()\n","    context = self(context)\n","    return context"],"metadata":{"id":"CncsOPQebmUK","executionInfo":{"status":"ok","timestamp":1682247658268,"user_tz":-330,"elapsed":714,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["# Encode the input sequence.\n","encoder = Encoder(context_text_processor, UNITS)\n","ex_context = encoder(ex_context_tok)\n","\n","print(f'Context tokens, shape (batch, s): {ex_context_tok.shape}')\n","print(f'Encoder output, shape (batch, s, units): {ex_context.shape}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"UXjmG0TvfMz2","executionInfo":{"status":"ok","timestamp":1682247667796,"user_tz":-330,"elapsed":3711,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}},"outputId":"bfa9e176-c7e8-47e5-f49a-14269d76d0a5"},"execution_count":24,"outputs":[{"output_type":"stream","name":"stdout","text":["Context tokens, shape (batch, s): (64, 17)\n","Encoder output, shape (batch, s, units): (64, 17, 256)\n"]}]},{"cell_type":"markdown","source":["**The attention layer**"],"metadata":{"id":"aLcBPEiJy39u"}},{"cell_type":"code","source":["class CrossAttention(tf.keras.layers.Layer):\n","  def __init__(self, units, **kwargs):\n","    super().__init__()\n","    self.mha = tf.keras.layers.MultiHeadAttention(key_dim=units, num_heads=1, **kwargs)\n","    self.layernorm = tf.keras.layers.LayerNormalization()\n","    self.add = tf.keras.layers.Add()\n","\n","  def call(self, x, context):\n","    shape_checker = ShapeChecker()\n","\n","    shape_checker(x, 'batch t units')\n","    shape_checker(context, 'batch s units')\n","\n","    attn_output, attn_scores = self.mha(\n","        query=x,\n","        value=context,\n","        return_attention_scores=True)\n","    \n","    shape_checker(x, 'batch t units')\n","    shape_checker(attn_scores, 'batch heads t s')\n","\n","    # Cache the attention scores for plotting later.\n","    attn_scores = tf.reduce_mean(attn_scores, axis=1)\n","    shape_checker(attn_scores, 'batch t s')\n","    self.last_attention_weights = attn_scores\n","\n","    x = self.add([x, attn_output])\n","    x = self.layernorm(x)\n","\n","    return x"],"metadata":{"id":"KGiCpW0Sft5d","executionInfo":{"status":"ok","timestamp":1682248316922,"user_tz":-330,"elapsed":8,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}}},"execution_count":25,"outputs":[]},{"cell_type":"code","source":["attention_layer = CrossAttention(UNITS)\n","\n","# Attend to the encoded tokens\n","embed = tf.keras.layers.Embedding(target_text_processor.vocabulary_size(),\n","                                  output_dim=UNITS, mask_zero=True)\n","ex_tar_embed = embed(ex_tar_in)\n","\n","result = attention_layer(ex_tar_embed, ex_context)\n","\n","print(f'Context sequence, shape (batch, s, units): {ex_context.shape}')\n","print(f'Target sequence, shape (batch, t, units): {ex_tar_embed.shape}')\n","print(f'Attention result, shape (batch, t, units): {result.shape}')\n","print(f'Attention weights, shape (batch, t, s):    {attention_layer.last_attention_weights.shape}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"C2viqtxU0DLZ","executionInfo":{"status":"ok","timestamp":1682248572700,"user_tz":-330,"elapsed":11,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}},"outputId":"3d3167cc-400c-4eab-b93d-7b511d1934dc"},"execution_count":28,"outputs":[{"output_type":"stream","name":"stdout","text":["Context sequence, shape (batch, s, units): (64, 17, 256)\n","Target sequence, shape (batch, t, units): (64, 14, 256)\n","Attention result, shape (batch, t, units): (64, 14, 256)\n","Attention weights, shape (batch, t, s):    (64, 14, 17)\n"]}]},{"cell_type":"markdown","source":["## The decoder"],"metadata":{"id":"njdvAU4l6mwP"}},{"cell_type":"code","source":["class Decoder(tf.keras.layers.Layer):\n","  @classmethod\n","  def add_method(cls, fun):\n","    setattr(cls, fun.__name__, fun)\n","    return fun\n","\n","  def __init__(self, text_processor, units):\n","    super(Decoder, self).__init__()\n","    self.text_processor = text_processor\n","    self.vocab_size = text_processor.vocabulary_size()\n","    self.word_to_id = tf.keras.layers.StringLookup(\n","        vocabulary=text_processor.get_vocabulary(),\n","        mask_token='', oov_token='[UNK]')\n","    self.id_to_word = tf.keras.layers.StringLookup(\n","        vocabulary=text_processor.get_vocabulary(),\n","        mask_token='', oov_token='[UNK]',\n","        invert=True)\n","    self.start_token = self.word_to_id('[START]')\n","    self.end_token = self.word_to_id('[END]')\n","\n","    self.units = units\n","\n","    self.embedding = tf.keras.layers.Embedding(self.vocab_size,\n","                                               units, mask_zero=True)\n","    \n","    self.rnn = tf.keras.layers.GRU(units, \n","                                   return_sequences=True,\n","                                   return_state=True,\n","                                   recurrent_initializer='glorot_uniform')\n","    \n","    self.attention = CrossAttention(units)\n","\n","    self.output_layer = tf.keras.layers.Dense(self.vocab_size)"],"metadata":{"id":"yqWDFgvg1LGg","executionInfo":{"status":"ok","timestamp":1682250681506,"user_tz":-330,"elapsed":673,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}}},"execution_count":31,"outputs":[]},{"cell_type":"code","source":["@Decoder.add_method\n","def call(self, context, x, state=None, return_state=False):\n","  shape_checker = ShapeChecker()\n","  shape_checker(x, 'batch t')\n","  shape_checker(context, 'batch s units')\n","\n","  x = self.embedding(x)\n","  shape_checker(x, 'batch t units')\n","\n","  x, state = self.rnn(x, initial_state=state)\n","  shape_checker(x, 'batch t units')\n","\n","  x = self.attention(x, context)\n","  self.last_attention_weights = self.attention.last_attention_weights\n","  shape_checker(x, 'batch t units')\n","  shape_checker(self.last_attention_weights, 'batch t s')\n","\n","  logits = self.output_layer(x)\n","  shape_checker(logits, 'batch t target_vocab_size')\n","\n","  if return_state:\n","    return logits, state\n","  else:\n","    return logits"],"metadata":{"id":"oRPoU2pA86QR","executionInfo":{"status":"ok","timestamp":1682251020145,"user_tz":-330,"elapsed":938,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}}},"execution_count":32,"outputs":[]},{"cell_type":"code","source":["decoder = Decoder(target_text_processor, UNITS)"],"metadata":{"id":"8hBO8cOu-XDy","executionInfo":{"status":"ok","timestamp":1682251056592,"user_tz":-330,"elapsed":895,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}}},"execution_count":33,"outputs":[]},{"cell_type":"code","source":["logits = decoder(ex_context, ex_tar_in)\n","\n","print(f'encoder output shape: (batch, s, units) {ex_context.shape}')\n","print(f'input target tokens shape: (batch, t) {ex_tar_in.shape}')\n","print(f'logits shape shape: (batch, target_vocabulary_size) {logits.shape}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"WVeTeIfh-fwA","executionInfo":{"status":"ok","timestamp":1682251102232,"user_tz":-330,"elapsed":1210,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}},"outputId":"f91594c3-7242-4a5f-f3ea-2b04290afc91"},"execution_count":34,"outputs":[{"output_type":"stream","name":"stdout","text":["encoder output shape: (batch, s, units) (64, 17, 256)\n","input target tokens shape: (batch, t) (64, 14)\n","logits shape shape: (batch, target_vocabulary_size) (64, 14, 5000)\n"]}]},{"cell_type":"code","source":["@Decoder.add_method\n","def get_initial_state(self, context):\n","  batch_size = tf.shape(context)[0]\n","  start_tokens = tf.fill([batch_size, 1], self.start_token)\n","  done = tf.zeros([batch_size, 1], dtype=tf.bool)\n","  embedded = self.embedding(start_tokens)\n","  return start_tokens, done, self.rnn.get_initial_state(embedded)[0]"],"metadata":{"id":"YSnMLN2K-rBZ","executionInfo":{"status":"ok","timestamp":1682251298316,"user_tz":-330,"elapsed":679,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}}},"execution_count":35,"outputs":[]},{"cell_type":"code","source":["@Decoder.add_method\n","def tokens_to_text(self, tokens):\n","  words = self.id_to_word(tokens)\n","  result = tf.strings.reduce_join(words, axis=-1, separator=' ')\n","  result = tf.strings.regex_replace(result, '^ *\\[START\\] *', '')\n","  result = tf.strings.regex_replace(result, ' *\\[END\\] *$', '')\n","  return result"],"metadata":{"id":"QABquWLG_bCg","executionInfo":{"status":"ok","timestamp":1682251443907,"user_tz":-330,"elapsed":765,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}}},"execution_count":36,"outputs":[]},{"cell_type":"code","source":["@Decoder.add_method\n","def get_next_token(self, context, next_token, done, state, temperature = 0.0):\n","  logits, state = self(\n","    context, next_token,\n","    state = state,\n","    return_state=True) \n","\n","  if temperature == 0.0:\n","    next_token = tf.argmax(logits, axis=-1)\n","  else:\n","    logits = logits[:, -1, :]/temperature\n","    next_token = tf.random.categorical(logits, num_samples=1)\n","\n","  # If a sequence produces an `end_token`, set it `done`\n","  done = done | (next_token == self.end_token)\n","  # Once a sequence is done it only produces 0-padding.\n","  next_token = tf.where(done, tf.constant(0, dtype=tf.int64), next_token)\n","\n","  return next_token, done, state"],"metadata":{"id":"hM14gIZP_-kE","executionInfo":{"status":"ok","timestamp":1682251492719,"user_tz":-330,"elapsed":720,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","source":["# Setup the loop variables.\n","next_token, done, state = decoder.get_initial_state(ex_context)\n","tokens = []\n","\n","for n in range(10):\n","  # Run one step.\n","  next_token, done, state = decoder.get_next_token(\n","      ex_context, next_token, done, state, temperature=1.0)\n","  # Add the token to the output.\n","  tokens.append(next_token)\n","\n","# Stack all the tokens together.\n","tokens = tf.concat(tokens, axis=-1) # (batch, t)\n","\n","# Convert the tokens back to a a string\n","result = decoder.tokens_to_text(tokens)\n","result[:3].numpy()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aejUiw4lAKeE","executionInfo":{"status":"ok","timestamp":1682251505306,"user_tz":-330,"elapsed":687,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}},"outputId":"9cab94ef-9093-47e3-a3b8-61a313e66fc1"},"execution_count":38,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([b'theyre reminded treasure change trim flipped untidy girls bowl selfish',\n","       b'neat leaving blanket volunteered sharp gentle arrest mail exam theyre',\n","       b'magic phrase terribly cycling programs engineer hesitate dug trees novelist'],\n","      dtype=object)"]},"metadata":{},"execution_count":38}]},{"cell_type":"markdown","source":["## The model"],"metadata":{"id":"Is1TCfBUAUep"}},{"cell_type":"code","source":["class Translator(tf.keras.Model):\n","  @classmethod\n","  def add_method(cls, fun):\n","    setattr(cls, fun.__name__, fun)\n","    return fun \n","\n","  def __init__(self, units, context_text_processor, target_text_processor):\n","    super().__init__()\n","    # Build the encoder and decoder\n","    encoder = Encoder(context_text_processor, units)\n","    decoder = Decoder(target_text_processor, units)\n","\n","    self.encoder = encoder\n","    self.decoder = decoder\n","\n","  def call(self, inputs):\n","    context, x = inputs\n","    context = self.encoder(context)\n","    logists = self.decoder(context, x)\n","\n","     #TODO(b/250038731): remove this\n","    try:\n","      # Delete the keras mask, so keras doesn't scale the loss+accuracy. \n","      del logits._keras_mask\n","    except AttributeError:\n","      pass\n","\n","    return logits"],"metadata":{"id":"f-X9epvMANiS","executionInfo":{"status":"ok","timestamp":1682251761815,"user_tz":-330,"elapsed":830,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}}},"execution_count":39,"outputs":[]},{"cell_type":"code","source":["model = Translator(UNITS, context_text_processor, target_text_processor)\n","\n","logits = model((ex_context_tok, ex_tar_in))\n","\n","print(f'Context tokens, shape: (batch, s, units) {ex_context_tok.shape}')\n","print(f'Target tokens, shape: (batch, t) {ex_tar_in.shape}')\n","print(f'logits, shape: (batch, t, target_vocabulary_size) {logits.shape}')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"flES7KE3BMHF","executionInfo":{"status":"ok","timestamp":1682251776608,"user_tz":-330,"elapsed":4805,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}},"outputId":"c43c71ef-e08c-4a51-9e96-8f7500d64238"},"execution_count":40,"outputs":[{"output_type":"stream","name":"stdout","text":["Context tokens, shape: (batch, s, units) (64, 17)\n","Target tokens, shape: (batch, t) (64, 14)\n","logits, shape: (batch, t, target_vocabulary_size) (64, 14, 5000)\n"]}]},{"cell_type":"code","source":["def masked_loss(y_true, y_pred):\n","    # Calculate the loss for each item in the batch.\n","    loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(\n","        from_logits=True, reduction='none')\n","    loss = loss_fn(y_true, y_pred)\n","\n","    # Mask off the losses on padding.\n","    mask = tf.cast(y_true != 0, loss.dtype)\n","    loss *= mask\n","\n","    # Return the total.\n","    return tf.reduce_sum(loss)/tf.reduce_sum(mask)"],"metadata":{"id":"0dPWnq9TBOCT","executionInfo":{"status":"ok","timestamp":1682251782875,"user_tz":-330,"elapsed":889,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","source":["def masked_acc(y_true, y_pred):\n","    # Calculate the loss for each item in the batch.\n","    y_pred = tf.argmax(y_pred, axis=-1)\n","    y_pred = tf.cast(y_pred, y_true.dtype)\n","\n","    match = tf.cast(y_true == y_pred, tf.float32)\n","    mask = tf.cast(y_true != 0, tf.float32)\n","\n","    return tf.reduce_sum(match)/tf.reduce_sum(mask)"],"metadata":{"id":"OqyUSpq9BRQh","executionInfo":{"status":"ok","timestamp":1682251788470,"user_tz":-330,"elapsed":692,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}}},"execution_count":42,"outputs":[]},{"cell_type":"code","source":["model.compile(optimizer='adam',\n","              loss=masked_loss, \n","              metrics=[masked_acc, masked_loss])"],"metadata":{"id":"1doqcNbhBSmb","executionInfo":{"status":"ok","timestamp":1682251802673,"user_tz":-330,"elapsed":710,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}}},"execution_count":43,"outputs":[]},{"cell_type":"code","source":["vocab_size = 1.0 * target_text_processor.vocabulary_size()\n","\n","{\"expected_loss\": tf.math.log(vocab_size).numpy(),\n"," \"expected_acc\": 1/vocab_size}"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vJIUix9QBWIr","executionInfo":{"status":"ok","timestamp":1682251807705,"user_tz":-330,"elapsed":817,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}},"outputId":"45e7e53f-01e4-4d41-9ffd-ca2459500c9c"},"execution_count":44,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'expected_loss': 8.517193, 'expected_acc': 0.0002}"]},"metadata":{},"execution_count":44}]},{"cell_type":"code","source":["history = model.fit(\n","    train_ds.repeat(), \n","    epochs=100,\n","    steps_per_epoch = 100,\n","    validation_data=val_ds,\n","    validation_steps = 20,\n","    callbacks=[\n","        tf.keras.callbacks.EarlyStopping(patience=3)])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"cAbFj35zBXUD","executionInfo":{"status":"error","timestamp":1682251824484,"user_tz":-330,"elapsed":5728,"user":{"displayName":"Sayan Dafadar","userId":"01489114010454149167"}},"outputId":"7e3253d2-5cb0-4ef4-cc68-f2ffe90c3737"},"execution_count":45,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/100\n"]},{"output_type":"error","ename":"ValueError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-45-5d46c8e20a54>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_ds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrepeat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m                     \u001b[0mretval_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconverted_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep_function\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mag__\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mld\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfscope\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m                 \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m                     \u001b[0mdo_return\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1284, in train_function  *\n        return step_function(self, iterator)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1268, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1249, in run_step  **\n        outputs = model.train_step(data)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/engine/training.py\", line 1054, in train_step\n        self.optimizer.minimize(loss, self.trainable_variables, tape=tape)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer.py\", line 543, in minimize\n        self.apply_gradients(grads_and_vars)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer.py\", line 1173, in apply_gradients\n        grads_and_vars = self.aggregate_gradients(grads_and_vars)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/optimizers/optimizer.py\", line 1139, in aggregate_gradients\n        return optimizer_utils.all_reduce_sum_gradients(grads_and_vars)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/optimizers/utils.py\", line 33, in all_reduce_sum_gradients\n        filtered_grads_and_vars = filter_empty_gradients(grads_and_vars)\n    File \"/usr/local/lib/python3.9/dist-packages/keras/optimizers/utils.py\", line 77, in filter_empty_gradients\n        raise ValueError(\n\n    ValueError: No gradients provided for any variable: (['translator/encoder_1/embedding_4/embeddings:0', 'translator/encoder_1/bidirectional_1/forward_gru_2/gru_cell_5/kernel:0', 'translator/encoder_1/bidirectional_1/forward_gru_2/gru_cell_5/recurrent_kernel:0', 'translator/encoder_1/bidirectional_1/forward_gru_2/gru_cell_5/bias:0', 'translator/encoder_1/bidirectional_1/backward_gru_2/gru_cell_6/kernel:0', 'translator/encoder_1/bidirectional_1/backward_gru_2/gru_cell_6/recurrent_kernel:0', 'translator/encoder_1/bidirectional_1/backward_gru_2/gru_cell_6/bias:0', 'translator/decoder_1/embedding_5/embeddings:0', 'translator/decoder_1/gru_3/gru_cell_7/kernel:0', 'translator/decoder_1/gru_3/gru_cell_7/recurrent_kernel:0', 'translator/decoder_1/gru_3/gru_cell_7/bias:0', 'translator/decoder_1/cross_attention_3/multi_head_attention_3/query/kernel:0', 'translator/decoder_1/cross_attention_3/multi_head_attention_3/query/bias:0', 'translator/decoder_1/cross_attention_3/multi_head_attention_3/key/kernel:0', 'translator/decoder_1/cross_attention_3/multi_head_attention_3/key/bias:0', 'translator/decoder_1/cross_attention_3/multi_head_attention_3/value/kernel:0', 'translator/decoder_1/cross_attention_3/multi_head_attention_3/value/bias:0', 'translator/decoder_1/cross_attention_3/multi_head_attention_3/attention_output/kernel:0', 'translator/decoder_1/cross_attention_3/multi_head_attention_3/attention_output/bias:0', 'translator/decoder_1/cross_attention_3/layer_normalization_3/gamma:0'...\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"NuE5lr9jBaQD"},"execution_count":null,"outputs":[]}]}